{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- https://pythondata.com/comparing-machine-learning-methods/\n",
    "- http://yann.lecun.com/exdb/mnist/ (accuracy of various models on the dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing library for time manipulation\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing librararies for data pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing libraries for machine learning (without neural network)\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Importing libraries for deep learning (CNN)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation\n",
    "\n",
    "# Importing libraries for evaluation\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH_train = 'C:\\\\Users\\\\sameer.rai\\\\Desktop\\\\Jupyter Notebooks\\\\Digit Recognizer\\\\Data\\\\train.csv'\n",
    "FILEPATH_test = 'C:\\\\Users\\\\sameer.rai\\\\Desktop\\\\Jupyter Notebooks\\\\Digit Recognizer\\\\Data\\\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(FILEPATH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and labels\n",
    "X = train_data.iloc[:, 1:].values\n",
    "y = train_data.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the array for plotting\n",
    "X_reshaped = np.reshape(X, (42000,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting sample inputs\n",
    "plt.imshow(X_reshaped[5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into training and cv set using pandas\n",
    "# train_set = train_data.sample(frac = 0.2, random_state = 0.0)\n",
    "# cv_set = train_data.drop(train_set.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and lables for traning dataset\n",
    "X = train_data.iloc[:, 1:].values\n",
    "y = train_data.iloc[:, 0].values\n",
    "\n",
    "# Dividing the dataset into training and cv set using much better method, sklearn train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 10)\n",
    "\n",
    "# Scaling X_train and X_cv\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536)}\n",
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631]), 'Random Forest': array([0.93457249, 0.93722107, 0.93183509, 0.93121929, 0.92943278])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536), 'Random Forest': datetime.timedelta(seconds=9, microseconds=472137)}\n",
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631]), 'Random Forest': array([0.93457249, 0.93722107, 0.93183509, 0.93121929, 0.92943278]), 'Support Vector': array([0.9729368 , 0.97426361, 0.97380563, 0.97156469, 0.97067143])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536), 'Random Forest': datetime.timedelta(seconds=9, microseconds=472137), 'Support Vector': datetime.timedelta(seconds=890, microseconds=981092)}\n",
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631]), 'Random Forest': array([0.93457249, 0.93722107, 0.93183509, 0.93121929, 0.92943278]), 'Support Vector': array([0.9729368 , 0.97426361, 0.97380563, 0.97156469, 0.97067143]), 'Linear Discriminator': array([0.86245353, 0.8673014 , 0.86381902, 0.86452285, 0.85603692])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536), 'Random Forest': datetime.timedelta(seconds=9, microseconds=472137), 'Support Vector': datetime.timedelta(seconds=890, microseconds=981092), 'Linear Discriminator': datetime.timedelta(seconds=23, microseconds=195650)}\n",
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631]), 'Random Forest': array([0.93457249, 0.93722107, 0.93183509, 0.93121929, 0.92943278]), 'Support Vector': array([0.9729368 , 0.97426361, 0.97380563, 0.97156469, 0.97067143]), 'Linear Discriminator': array([0.86245353, 0.8673014 , 0.86381902, 0.86452285, 0.85603692]), 'Gaussian NB': array([0.53828996, 0.56887831, 0.55796994, 0.54845913, 0.54697037])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536), 'Random Forest': datetime.timedelta(seconds=9, microseconds=472137), 'Support Vector': datetime.timedelta(seconds=890, microseconds=981092), 'Linear Discriminator': datetime.timedelta(seconds=23, microseconds=195650), 'Gaussian NB': datetime.timedelta(seconds=7, microseconds=600961)}\n",
      "{'Logistic Regression': array([0.91762082, 0.91922047, 0.9130823 , 0.91528956, 0.91439631]), 'Random Forest': array([0.93457249, 0.93722107, 0.93183509, 0.93121929, 0.92943278]), 'Support Vector': array([0.9729368 , 0.97426361, 0.97380563, 0.97156469, 0.97067143]), 'Linear Discriminator': array([0.86245353, 0.8673014 , 0.86381902, 0.86452285, 0.85603692]), 'Gaussian NB': array([0.53828996, 0.56887831, 0.55796994, 0.54845913, 0.54697037]), 'K-neighbours': array([0.96550186, 0.9648914 , 0.96398274, 0.96069674, 0.96025011])}\n",
      "{'Logistic Regression': datetime.timedelta(seconds=176, microseconds=382536), 'Random Forest': datetime.timedelta(seconds=9, microseconds=472137), 'Support Vector': datetime.timedelta(seconds=890, microseconds=981092), 'Linear Discriminator': datetime.timedelta(seconds=23, microseconds=195650), 'Gaussian NB': datetime.timedelta(seconds=7, microseconds=600961), 'K-neighbours': datetime.timedelta(seconds=1175, microseconds=950308)}\n",
      "                             0         1         2         3         4\n",
      "Logistic Regression   0.917621  0.919220  0.913082  0.915290  0.914396\n",
      "Random Forest         0.934572  0.937221  0.931835  0.931219  0.929433\n",
      "Support Vector        0.972937  0.974264  0.973806  0.971565  0.970671\n",
      "Linear Discriminator  0.862454  0.867301  0.863819  0.864523  0.856037\n",
      "Gaussian NB           0.538290  0.568878  0.557970  0.548459  0.546970\n",
      "K-neighbours          0.965502  0.964891  0.963983  0.960697  0.960250\n",
      "                                   0\n",
      "Logistic Regression  00:02:56.382536\n",
      "Random Forest        00:00:09.472137\n",
      "Support Vector       00:14:50.981092\n",
      "Linear Discriminator 00:00:23.195650\n",
      "Gaussian NB          00:00:07.600961\n",
      "K-neighbours         00:19:35.950308\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial'),\n",
    "    'Random Forest' : RandomForestClassifier(),\n",
    "    'Support Vector' : SVC(gamma='scale'),\n",
    "    'Linear Discriminator' : LinearDiscriminantAnalysis(),\n",
    "    'Gaussian NB' : GaussianNB(),\n",
    "    'K-neighbours': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "Evaulation_result = {}\n",
    "time = {}\n",
    "\n",
    "# Iterating through all the models and using sklearn.model_selection.cross_val_score\n",
    "for name, model in models.items():\n",
    "    start_time = datetime.now()\n",
    "    results = model_selection.cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5, scoring = 'accuracy' )\n",
    "    end_time = datetime.now()\n",
    "    time_taken = end_time - start_time\n",
    "    time.update({name:time_taken})\n",
    "    Evaulation_result.update({name : results})\n",
    "    print(Evaulation_result)\n",
    "    print(time)\n",
    "    \n",
    "# print(Evaulation_result)\n",
    "\n",
    "evaluation_result = pd.DataFrame.from_dict(Evaulation_result, orient='index')\n",
    "Time = pd.DataFrame.from_dict(time, orient='index')\n",
    "print(evaluation_result)\n",
    "print(Time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANY0lEQVR4nO3df6jd913H8efLpKXaLW2uuY7S1CZCNlKK2HEJSGFrnZN0jlYdSAITlLD+Y+P8TWtkTQvFf0SFUoXSTjddGkLnNEixynKHRjbNzdpuTbKMEDd7jdK7pVutUJLGt3/cs3q9uT9OknPP955Png+47J5zvjnf9/ePPfn28/2ec1NVSJJG3/d1PYAkaTAMuiQ1wqBLUiMMuiQ1wqBLUiPWdrXjDRs21KZNm7ravSSNpKNHj36rqsYXeq2zoG/atImpqamudi9JIynJNxd7zSUXSWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0DdXY2BhJhvYzNjbW9SFLQ9PZJ0V1dTr7KxeAdUPc44Uh7kvqlkHXcO397qIvJbnst/Uvb0kGXauIUZaujGvokkQb13c8Q5ck2ri+Y9AlCcgjrw91f+vXr+fs3sG+p0GXJJa+hjMqF+wNuiQtY1Qu2HtRVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRF+sGiEjMqn1SR1wzP0VWapb3y7Ev5FH6l9nqGvMi1845ukbhj0VaaFb3yT1A2Dvsq08I1vkrph0EeIUZa0FC+KSlIjDLokNaKpJRfXmCVdzUbuDN37tCVpYSN3hu592pK0sJELOnu/u+hLLrlIupqNXtCXYJQlXc1Gbg1dkrSwvoKeZHuSk0lOJXlwgddvTfL5JF9J8oUkGwc/qiRpKcsGPcka4AngHuA2YGeS2+Zt9vvAp6vqR4FHgd8b9KCSpKX1c4a+DThVVaer6hywH7hv3ja3AZ/v/T65wOuSpBXWT9BvBl6Z83i699xcLwEf6f3+s8A7k/zg/DdKcn+SqSRTMzMzlzOvJGkR/QR9oXsB599O8pvA+5O8ALwf+HfgrYv+UdWTVTVRVRPj4+OXPKwkaXH93LY4Ddwy5/FG4MzcDarqDPBzAEneAXykqha/YVySNHD9nKEfAbYk2ZzkWmAHcHDuBkk2JPneez0EfHKwY0qSlrNs0KvqLeAB4HngBHCgqo4leTTJvb3N7gJOJvk68C7gsRWaV5K0iHT16cqJiYmamprqZN+SNKqSHK2qiYVe85OiktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktSIpv6mqLRa+QfMNQwGXRqUvTcs+lI9vG5F3pe9fqmp/o9BlwYkj7w+1P2tX7+es3uHukutcq6hSwNSVX3/7Nu3j82bN3Po0CHOnTvHoUOH2Lx5M/v27ev7Pc6ePdv1IWuV8dsWpQ7cfvvtPP7449x9991vPzc5Ocnu3bt5+eWXO5xMq91S37Zo0KUOrFmzhjfffJNrrrnm7efOnz/Pddddx4ULFzqcTKudX58rrTJbt27l8OHD/++5w4cPs3Xr1o4mUgsMutSBPXv2sGvXLiYnJzl//jyTk5Ps2rWLPXv2dD2aRph3uUgd2LlzJwC7d+/mxIkTbN26lccee+zt56XL4Rq6JI0Q19Al6Spg0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhrRV9CTbE9yMsmpJA8u8PoPJ5lM8kKSryT50OBHlSQtZdmgJ1kDPAHcA9wG7Exy27zNfhc4UFV3ADuAPx70oJKkpfVzhr4NOFVVp6vqHLAfuG/eNgWs6/1+A3BmcCNKkvrRT9BvBl6Z83i699xce4GPJpkGngN2L/RGSe5PMpVkamZm5jLGlSQtpp+gZ4Hnat7jncCfVdVG4EPAnye56L2r6smqmqiqifHx8UufVpK0qH6CPg3cMufxRi5eUtkFHACoqi8C1wEbBjGgJKk//QT9CLAlyeYk1zJ70fPgvG3+DfgAQJKtzAbdNRVJGqJlg15VbwEPAM8DJ5i9m+VYkkeT3Nvb7DeAjyV5CXgG+MWqmr8sI0laQWv72aiqnmP2Yufc5z4x5/fjwJ2DHU2SdCn8pKgkNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1Ij+gp6ku1JTiY5leTBBV7/wyQv9n6+nuQ7gx9VkrSUtcttkGQN8ATwQWAaOJLkYFUd/942VfVrc7bfDdyxArNKkpbQzxn6NuBUVZ2uqnPAfuC+JbbfCTwziOEkSf3rJ+g3A6/MeTzde+4iSW4FNgOHrnw0SdKl6CfoWeC5WmTbHcCzVXVhwTdK7k8ylWRqZmam3xklSX3oJ+jTwC1zHm8Eziyy7Q6WWG6pqieraqKqJsbHx/ufUpK0rH6CfgTYkmRzkmuZjfbB+RsleQ+wHvjiYEeUJPVj2aBX1VvAA8DzwAngQFUdS/JoknvnbLoT2F9Viy3HSJJW0LK3LQJU1XPAc/Oe+8S8x3sHN5Yk6VL5SVFJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJakRfQU+yPcnJJKeSPLjINj+f5HiSY0n2DXZMSdJy1i63QZI1wBPAB4Fp4EiSg1V1fM42W4CHgDur6rUkP7RSA0uSFtbPGfo24FRVna6qc8B+4L5523wMeKKqXgOoqlcHO6YkaTn9BP1m4JU5j6d7z831buDdSf4pyZeSbF/ojZLcn2QqydTMzMzlTSxJWlA/Qc8Cz9W8x2uBLcBdwE7gqSQ3XvSPqp6sqomqmhgfH7/UWSVJS+gn6NPALXMebwTOLLDNX1fV+ar6V+Aks4GXJA1JP0E/AmxJsjnJtcAO4OC8bf4KuBsgyQZml2BOD3JQSdLSlg16Vb0FPAA8D5wADlTVsSSPJrm3t9nzwLeTHAcmgd+qqm+v1NCSpIulav5y+HBMTEzU1NRUJ/uWpFGV5GhVTSz0mp8UlaRGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJasSy34cuSctJFvoOv/509eHGFhl0SVdsqSgnMdpD4pKLJDXCoEtSIwy6JDXCoEvqy9jYGEku+Qe4rH83NjbW8RGPHi+KSurLa6+9NtSLm1dy58zVyjN0SWqEQZekRrjkIqkv9fA62HvDcPenS2LQJfUlj7w+1P2tX7+es3uHusuRZ9Al9eVyL4j6SdHhcQ1dkhph0CWpES65SLpiy90zvtTrLscMjkGXdMWM8urgkoskNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1Ij0tUHApLMAN8c4i43AN8a4v6GzeMbXS0fG3h8g3ZrVY0v9EJnQR+2JFNVNdH1HCvF4xtdLR8beHzD5JKLJDXCoEtSI66moD/Z9QArzOMbXS0fG3h8Q3PVrKFLUuuupjN0SWqaQZekRjQf9CSfTPJqkpe7nmXQktySZDLJiSTHkny865kGKcl1Sf4lyUu943uk65lWQpI1SV5I8jddzzJoSb6R5KtJXkwy1fU8g5bkxiTPJvla7/+HP97pPK2voSd5H/AG8Omqur3reQYpyU3ATVX15STvBI4CP1NVxzsebSAy+3fLrq+qN5JcAxwGPl5VX+p4tIFK8uvABLCuqj7c9TyDlOQbwERVNfnBoiSfAv6xqp5Kci3wA1X1na7maf4Mvar+ATjb9Rwroar+o6q+3Pv9v4ATwM3dTjU4NeuN3sNrej9NnYEk2Qj8NPBU17Po0iRZB7wPeBqgqs51GXO4CoJ+tUiyCbgD+OduJxms3nLEi8CrwN9XVVPHB/wR8NvA/3Q9yAop4O+SHE1yf9fDDNiPADPAn/aWzJ5Kcn2XAxn0BiR5B/BZ4Fer6vWu5xmkqrpQVT8GbAS2JWlm2SzJh4FXq+po17OsoDur6r3APcAv95ZAW7EWeC/wJ1V1B/DfwINdDmTQR1xvbfmzwGeq6i+7nmel9P5T9gvA9o5HGaQ7gXt768z7gZ9I8hfdjjRYVXWm97+vAp8DtnU70UBNA9Nz/qvxWWYD3xmDPsJ6Fw2fBk5U1R90Pc+gJRlPcmPv9+8HfhL4WrdTDU5VPVRVG6tqE7ADOFRVH+14rIFJcn3vYj29pYifApq526yq/hN4Jcl7ek99AOj0hoS1Xe58GJI8A9wFbEgyDTxcVU93O9XA3An8AvDV3jozwO9U1XMdzjRINwGfSrKG2ZOPA1XV3K19DXsX8LnZ8w7WAvuq6m+7HWngdgOf6d3hchr4pS6Haf62RUm6WrjkIkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmN+F85FJMRr0s0UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(evaluation_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Blue'>Next steps ??<font>\n",
    "    - May be, Grid Search\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nknn_obj = KNeighborsClassifier(n_neighbors = 10)\\nknn_obj.fit(X = X_train, y = y_train)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "knn_obj = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn_obj.fit(X = X_train, y = y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_train_pred_knn = knn_obj.predict(X_train)\\ny_test_pred_knn = knn_obj.predict(X_test)\\n\\nprint(\"Accuracy on training set for knn model: {}.\".format(metrics.accuracy_score(y_train, y_train_pred_knn)))\\nprint(\"Accuracy on test set for knn model: {}.\".format(metrics.accuracy_score(y_test, y_test_pred_knn)))\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_train_pred_knn = knn_obj.predict(X_train)\n",
    "y_test_pred_knn = knn_obj.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on training set for knn model: {}.\".format(metrics.accuracy_score(y_train, y_train_pred_knn)))\n",
    "print(\"Accuracy on test set for knn model: {}.\".format(metrics.accuracy_score(y_test, y_test_pred_knn)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_obj = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')\n",
    "lr_obj.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_obj.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3281,    0,    5,    3,    4,   12,   13,    3,   13,    2],\n",
       "       [   0, 3672,    8,   12,    0,    9,    4,    5,   22,    6],\n",
       "       [   9,   17, 3087,   40,   27,   14,   22,   32,   57,   16],\n",
       "       [   3,   10,   57, 3226,    1,   95,    8,   19,   51,   25],\n",
       "       [   2,   14,   11,    2, 3086,    2,   22,    7,   16,   84],\n",
       "       [  26,   10,   22,   90,   29, 2735,   34,    6,   53,   17],\n",
       "       [  18,    5,   13,    0,   11,   26, 3266,    0,   10,    1],\n",
       "       [   1,   11,   29,   10,   14,    3,    2, 3366,    6,   90],\n",
       "       [  14,   42,   17,   74,    8,   60,    9,    7, 2962,   34],\n",
       "       [  10,   13,    7,   34,   60,   18,    0,   76,   17, 3098]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set for lr model: 0.9458035714285714.\n",
      "Accuracy on test set for lr model: 0.9186904761904762.\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_lr = lr_obj.predict(X_train)\n",
    "y_test_pred_lr = lr_obj.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on training set for lr model: {}.\".format(metrics.accuracy_score(y_train, y_train_pred_lr)))\n",
    "print(\"Accuracy on test set for lr model: {}.\".format(metrics.accuracy_score(y_test, y_test_pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating object and fitting training dataset\n",
    "svc_obj = SVC(gamma='scale')\n",
    "svc_obj.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3324    0    1    1    2    1    3    0    3    1]\n",
      " [   0 3719    7    4    1    1    0    2    2    2]\n",
      " [   2    1 3294    5    5    0    0    7    5    2]\n",
      " [   0    1   13 3430    0   19    1    9   11   11]\n",
      " [   2    5    0    0 3206    0    3    3    0   27]\n",
      " [   4    2    1   15    3 2983    8    1    2    3]\n",
      " [   4    0    1    0    2    5 3334    0    4    0]\n",
      " [   2   14    7    3    8    0    0 3479    0   19]\n",
      " [   1    8    7    7    4    3    1    4 3190    2]\n",
      " [   7    4    1   11   24    2    1   21    4 3258]]\n",
      "Accuracy on training set for SVC model: 0.9886011904761904.\n",
      "Accuracy on test set for SVC model: 0.9757142857142858.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of SVC: Accuracy and confusion matrix \n",
    "# y_pred_svc = svc_obj.predict(X_train)\n",
    "\n",
    "y_train_pred_svc = svc_obj.predict(X_train)\n",
    "y_test_pred_svc = svc_obj.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_train, y_train_pred_svc))\n",
    "\n",
    "print(\"Accuracy on training set for SVC model: {}.\".format(metrics.accuracy_score(y_train, y_train_pred_svc)))\n",
    "print(\"Accuracy on test set for SVC model: {}.\".format(metrics.accuracy_score(y_test, y_test_pred_svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3336\n",
      "           1       0.99      0.99      0.99      3738\n",
      "           2       0.99      0.99      0.99      3321\n",
      "           3       0.99      0.98      0.98      3495\n",
      "           4       0.98      0.99      0.99      3246\n",
      "           5       0.99      0.99      0.99      3022\n",
      "           6       0.99      1.00      1.00      3350\n",
      "           7       0.99      0.98      0.99      3532\n",
      "           8       0.99      0.99      0.99      3227\n",
      "           9       0.98      0.98      0.98      3333\n",
      "\n",
      "    accuracy                           0.99     33600\n",
      "   macro avg       0.99      0.99      0.99     33600\n",
      "weighted avg       0.99      0.99      0.99     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of SVC: Classification report\n",
    "print(metrics.classification_report(y_train, y_train_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
